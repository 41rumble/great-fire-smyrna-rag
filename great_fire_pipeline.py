[{
  "id": "great_fire_qa",
  "name": "Great Fire of Smyrna QA",
  "type": "pipe",
  "content": "from typing import Union, List, Generator, Iterator\nfrom pydantic import BaseModel, Field\nimport requests\nimport json\n\nclass Pipe:\n    class Valves(BaseModel):\n        server_url: str = Field(\n            default=\"http://localhost:8002\",\n            description=\"Great Fire QA server URL\"\n        )\n        analysis_type: str = Field(\n            default=\"comprehensive\",\n            description=\"Analysis type: comprehensive, character_analysis, story_progression, relationships, themes, temporal\"\n        )\n        trigger_keywords: str = Field(\n            default=\"great fire,smyrna,jennings,atatÃ¼rk,bristol,1922,evacuation,humanitarian,turkish,greek,armenian,horton,kemal\",\n            description=\"Comma-separated keywords that trigger this pipeline\"\n        )\n        min_confidence: float = Field(\n            default=0.7,\n            description=\"Minimum confidence threshold for triggering (0.0-1.0)\"\n        )\n        enable_auto_detection: bool = Field(\n            default=True,\n            description=\"Enable automatic query type detection\"\n        )\n\n    def __init__(self):\n        self.type = \"pipe\"\n        self.id = \"great_fire_qa\"\n        self.name = \"Great Fire of Smyrna QA\"\n        self.valves = self.Valves()\n\n    def should_trigger(self, message: str) -> float:\n        \"\"\"Calculate confidence score for whether this query should trigger Great Fire analysis\"\"\"\n        keywords = [k.strip().lower() for k in self.valves.trigger_keywords.split(\",\")]\n        message_lower = message.lower()\n        \n        # Count keyword matches\n        matches = sum(1 for keyword in keywords if keyword in message_lower)\n        \n        # Calculate confidence based on matches and message length\n        if matches == 0:\n            return 0.0\n        \n        # Base confidence from keyword density\n        keyword_density = matches / len(keywords)\n        \n        # Boost for specific high-value terms\n        high_value_terms = [\"great fire\", \"smyrna\", \"jennings\", \"atatÃ¼rk\", \"1922\"]\n        high_value_matches = sum(1 for term in high_value_terms if term in message_lower)\n        \n        # Calculate final confidence\n        confidence = min(1.0, keyword_density + (high_value_matches * 0.2))\n        \n        return confidence\n\n    def pipe(\n        self,\n        user_message: str,\n        model_id: str,\n        messages: List[dict],\n        body: dict\n    ) -> Union[str, Generator, Iterator]:\n        \n        # Check if query should trigger Great Fire analysis\n        confidence = self.should_trigger(user_message)\n        \n        if confidence < self.valves.min_confidence:\n            # Not confident this is a Great Fire query, pass through\n            return None\n            \n        print(f\"ðŸ”¥ Great Fire QA triggered (confidence: {confidence:.2f}): {user_message[:50]}...\")\n        \n        try:\n            # Prepare request payload\n            payload = {\n                \"query\": user_message,\n                \"analysis_type\": self.valves.analysis_type if not self.valves.enable_auto_detection else \"comprehensive\"\n            }\n            \n            response = requests.post(\n                f\"{self.valves.server_url}/api/analyze\",\n                json=payload,\n                headers={\"Content-Type\": \"application/json\"},\n                timeout=60\n            )\n            \n            if response.status_code == 200:\n                qa_response = response.json()\n                answer = qa_response.get(\"answer\", \"No answer generated\")\n                analysis_type = qa_response.get(\"analysis_type\", \"unknown\")\n                entities_found = qa_response.get(\"entities_found\", 0)\n                processing_time = qa_response.get(\"processing_time\", 0)\n                query_type = qa_response.get(\"query_type_detected\", \"general\")\n                \n                # Format the response with rich metadata\n                formatted_response = f\"\"\"ðŸ“š **The Great Fire of Smyrna - Historical Analysis**\n\n{answer}\n\n---\n*ðŸŽ­ Analysis: {analysis_type.replace('_', ' ').title()} | ðŸ” Query Type: {query_type.replace('_', ' ').title()} | âš¡ {processing_time}s | ðŸ“Š {entities_found} entities*\n*ðŸ”¥ Specialized historical knowledge from deep narrative analysis*\"\"\"\n                \n                return formatted_response\n                \n            elif response.status_code == 404:\n                return \"âŒ Great Fire QA server not found. Please ensure the server is running on the configured URL.\"\n            elif response.status_code == 500:\n                error_detail = response.json().get(\"detail\", \"Internal server error\")\n                return f\"âš ï¸ Great Fire QA server error: {error_detail}\"\n            else:\n                return f\"âŒ Great Fire QA server returned status {response.status_code}\"\n                \n        except requests.exceptions.ConnectionError:\n            return \"ðŸ”Œ Cannot connect to Great Fire QA server. Please check if the server is running.\"\n        except requests.exceptions.Timeout:\n            return \"â±ï¸ Great Fire QA server request timed out. Complex analysis may take longer.\"\n        except Exception as e:\n            return f\"âŒ Great Fire QA error: {str(e)}\"\n",
  "meta": {\n    "description": "Specialized QA pipeline for The Great Fire of Smyrna (1922) with deep narrative analysis, character arcs, story progression, and thematic insights",\n    "manifest": {\n      "title": "Great Fire of Smyrna QA Pipeline",\n      "author": "Claude",\n      "version": "1.0.0",\n      "tags": ["historical", "narrative", "analysis", "qa", "1922", "smyrna"]\n    }\n  }\n}]